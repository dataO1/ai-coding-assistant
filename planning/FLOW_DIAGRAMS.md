# High-Level Flow Diagrams for Agentic IDE

## FLOW 1: System Architecture Overview (Three Packages)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AGENTIC IDE SYSTEM ARCHITECTURE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    PACKAGE 1: GUI CLIENT     â”‚
â”‚    (Rust + Iced)             â”‚
â”‚    Independent Executable    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ HTTP/WebSocket
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               PACKAGE 2: AGENT NETWORK BACKEND                   â”‚
â”‚                  (Python + LangChain + LangGraph)                â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ACP Server (Agent Client Protocol)                    â”‚   â”‚
â”‚  â”‚  - Handles GUI connections                              â”‚   â”‚
â”‚  â”‚  - Manages workflow execution                           â”‚   â”‚
â”‚  â”‚  - Streams callbacks (real-time updates)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚              â”‚              â”‚                       â”‚
â”‚           â–¼              â–¼              â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚Orchestrator  â”‚ â”‚Code Gen Agentâ”‚ â”‚Retrieval     â”‚            â”‚
â”‚  â”‚Agent         â”‚ â”‚              â”‚ â”‚Agent         â”‚            â”‚
â”‚  â”‚(Mistral-7B)  â”‚ â”‚(Mistral-7B)  â”‚ â”‚(Autonomous)  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚              â”‚              â”‚                       â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                     â”‚                                           â”‚
â”‚                     â–¼                                           â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚           â”‚   Ollama Server     â”‚                              â”‚
â”‚           â”‚ Async Streaming     â”‚                              â”‚
â”‚           â”‚ (localhost:11434)   â”‚                              â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²
         â”‚ HTTP
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PACKAGE 3: VECTOR DATABASE   â”‚
â”‚    (Qdrant)                  â”‚
â”‚    Collections:              â”‚
â”‚  - workspace_files (Phase 1) â”‚
â”‚  - workspace_functions       â”‚
â”‚    (Phase 2 AST)             â”‚
â”‚    (localhost:6333)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  External Services (via MCP)    â”‚
â”‚  - LSP Servers (Python, Rust,  â”‚
â”‚    JavaScript)                 â”‚
â”‚  - Git CLI                      â”‚
â”‚  - Code Formatters (Black,      â”‚
â”‚    autopep8, prettier)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## FLOW 2: Complete Feature Implementation Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FEATURE IMPLEMENTATION: User Request â†’ Code Delivery            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER INTERACTION PHASE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User Types Feature Request    â”‚
â”‚    "Implement JWT authentication"â”‚
â”‚    in GUI Interaction Window     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. GUI Sends Request via ACP                         â”‚
â”‚    POST /api/workflow/submit                         â”‚
â”‚    {                                                  â”‚
â”‚      workflow_type: "feature_implementation",        â”‚
â”‚      user_query: "Implement JWT auth",               â”‚
â”‚      correlation_id: "req_xyz"                       â”‚
â”‚    }                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼ (HTTP)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BACKEND PHASE 1: RETRIEVAL                           â”‚
â”‚                                                       â”‚
â”‚ 3a. Autonomous Retrieval Agent                       â”‚
â”‚     - Generates search query from user input         â”‚
â”‚     - "JWT implementation patterns"                  â”‚
â”‚                                                       â”‚
â”‚ 3b. Phase 1 File-Level Retrieval                     â”‚
â”‚     Query Qdrant collection: workspace_files         â”‚
â”‚     Vector search (nomic-embed-text) on CPU          â”‚
â”‚     Filter: exclude tests, max_size 500KB            â”‚
â”‚     Returns: Top 50 files by relevance               â”‚
â”‚     Latency: ~1.5 seconds                            â”‚
â”‚                                                       â”‚
â”‚ 3c. Phase 2 Function-Level AST Extraction            â”‚
â”‚     Selective AST parsing on retrieved files         â”‚
â”‚     Extract functions/classes with signatures        â”‚
â”‚     Cross-encoder reranking (MS-MARCO-MiniLM CPU)    â”‚
â”‚     Returns: Top 20 functions, context ~2500 tokens  â”‚
â”‚     Latency: ~1 second                               â”‚
â”‚                                                       â”‚
â”‚ âœ“ Context Ready: ~2500 tokens of relevant code       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BACKEND PHASE 2: PLANNING & WORKFLOW SELECTION       â”‚
â”‚                                                       â”‚
â”‚ 4. Orchestrator Agent (Mistral-7B Q4)                â”‚
â”‚    - Input: User query + retrieved context           â”‚
â”‚    - Reasoning: "This is a new feature implementation"
â”‚    - Decides workflow stages to execute:             â”‚
â”‚      âœ“ Code Generation                               â”‚
â”‚      âœ“ Test Generation                               â”‚
â”‚      âœ— Security Analysis (not critical for this)     â”‚
â”‚    - Passes: user_query + context to code_gen        â”‚
â”‚    - Latency: ~45 seconds (20-30 tokens)             â”‚
â”‚                                                       â”‚
â”‚ âœ“ Workflow Decided                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BACKEND PHASE 3: CODE GENERATION                     â”‚
â”‚                                                       â”‚
â”‚ 5. Code Generation Agent (Mistral-7B Q4, same model) â”‚
â”‚    - Ollama: keep_alive="-1" (already loaded)        â”‚
â”‚    - Input: context + specialized prompt             â”‚
â”‚    - Generation via streaming:                       â”‚
â”‚      â€¢ Emit token stream to GUI every 5 tokens       â”‚
â”‚      â€¢ GUI shows code in real-time (optimistic)      â”‚
â”‚                                                       â”‚
â”‚    Generated output:                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚    â”‚ def create_jwt_token(payload):    â”‚             â”‚
â”‚    â”‚     secret = os.getenv("JWT_KEY") â”‚             â”‚
â”‚    â”‚     token = jwt.encode(           â”‚             â”‚
â”‚    â”‚         payload, secret,          â”‚             â”‚
â”‚    â”‚         algorithm="HS256"         â”‚             â”‚
â”‚    â”‚     )                             â”‚             â”‚
â”‚    â”‚     return token                  â”‚             â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                       â”‚
â”‚ 6. MCP Tool: Black Formatter                         â”‚
â”‚    - Auto-format generated code                      â”‚
â”‚    - LSP Hover: Check types via Python LSP           â”‚
â”‚                                                       â”‚
â”‚ âœ“ Formatted Code Ready                               â”‚
â”‚    Latency: ~60 seconds (2000+ tokens)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                      â”‚
           â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 4a:          â”‚  â”‚ PHASE 4b:            â”‚
â”‚ Test Generation    â”‚  â”‚ GUI Display Diff     â”‚
â”‚                    â”‚  â”‚                      â”‚
â”‚ 7. Test Agent      â”‚  â”‚ â€¢ Show side-by-side  â”‚
â”‚    Generate tests  â”‚  â”‚   original vs new    â”‚
â”‚    for function    â”‚  â”‚ â€¢ Highlight changes  â”‚
â”‚    Latency: ~50s   â”‚  â”‚ â€¢ Footer: status bar â”‚
â”‚    Returns:        â”‚  â”‚ â€¢ Streaming tokens   â”‚
â”‚    pytest cases    â”‚  â”‚   as they arrive     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                      â–²
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER REVIEW PHASE                                    â”‚
â”‚                                                       â”‚
â”‚ 8. User Reviews Generated Code in GUI                â”‚
â”‚    Options:                                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚    â”‚ âœ“ Accept Changes                        â”‚      â”‚
â”‚    â”‚ âœ— Reject Changes                        â”‚      â”‚
â”‚    â”‚ ğŸ’­ Request Modifications (Feedback)     â”‚      â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
           â–¼                 â–¼                  â–¼
      ACCEPT            MODIFICATIONS         REJECT
       â”‚                    â”‚                  â”‚
       â–¼                    â–¼                  â–¼
    Apply to        Restart Workflow      Discard
    Workspace       (Full Pipeline)       Changes
    + Commit        New iteration         â”‚
    to Git          with feedback         â”‚
                    context               â–¼
                                      No Action
                                      (Back to IDE)
```

---

## FLOW 3: Real-Time Streaming (ACP Callbacks)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          STREAMING UPDATES: Backend â†’ GUI (Event-Based, No Polling)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Backend LLM Inference (Ollama Streaming):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Token Stream:  def â”‚ calculate â”‚ _sum â”‚ ( â”‚ a â”‚ , â”‚ b â”‚ ) â”‚ : â”‚ \n
                 T1      T2        T3    T4  T5  T6  T7  T8  T9  T10

Every 5 tokens, emit callback:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

T1-T5:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ACP Callback Event                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ {                                        â”‚
â”‚   "type": "agent_streaming_update",     â”‚
â”‚   "workflow_id": "feature_001",          â”‚
â”‚   "stage_id": "code_generation",         â”‚
â”‚   "partial_result":                      â”‚
â”‚     "def calculate_sum(a, b",            â”‚
â”‚   "tokens_so_far": 5,                    â”‚
â”‚   "is_final": false,                     â”‚
â”‚   "timestamp": 1234567890                â”‚
â”‚ }                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ HTTP (event-based, NOT polling)
           â–¼
GUI receives callback (Correlation ID req_xyz):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

GUI Update (Optimistic Rendering):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Main Window (Right Pane):       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ def calculate_sum(a, b   â”‚   â”‚  â† Highlight new content
â”‚ â”‚                          â”‚   â”‚
â”‚ â”‚                          â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                â”‚
â”‚ Footer Status:                 â”‚
â”‚ "Generating... 5 tokens"       â”‚
â”‚ Latency: ~150ms from backend   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


T6-T10:
Backend emits next callback:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {                                        â”‚
â”‚   "partial_result": "def calculate_sum", â”‚
â”‚     (a, b):",                            â”‚
â”‚   "tokens_so_far": 10,                   â”‚
â”‚   "is_final": false                      â”‚
â”‚ }                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼ (Latency ~100-200ms per callback)
GUI Updates:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ def calculate_sum(a, b):        â”‚
â”‚                                â”‚
â”‚ Footer: "Generating... 10 tok" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Final Callback (is_final=true):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {                                            â”‚
â”‚   "type": "agent_streaming_update",          â”‚
â”‚   "partial_result": "def calculate_sum(a,..  â”‚
â”‚     ...full code...",                        â”‚
â”‚   "tokens_so_far": 78,                       â”‚
â”‚   "is_final": true,                          â”‚
â”‚   "metrics": {                               â”‚
â”‚     "generation_time_sec": 3.5,              â”‚
â”‚     "tokens_per_sec": 22.3                   â”‚
â”‚   }                                          â”‚
â”‚ }                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
GUI Final Update + Ready for Review:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ def calculate_sum(a, b):           â”‚
â”‚     return a + b                   â”‚
â”‚                                    â”‚
â”‚ Footer: "âœ“ Complete (3.5s, 22 tok)"â”‚
â”‚ Buttons: [Accept] [Reject] [Mod]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total End-to-End Latency: ~3.5 seconds (inference)
                         + 0.1-0.2s per callback (network)
                         = Smooth real-time experience
```

---

## FLOW 4: User Feedback Loop (Iterative Refinement)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    USER FEEDBACK: Critique â†’ Restart Workflow â†’ Improved Output        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ITERATION 1:
â”â”â”â”â”â”â”â”â”â”â”

User: "Implement JWT auth"
       â”‚
       â–¼ (Full pipeline: Retrieval â†’ Planning â†’ Generation)
Generated Code (v1):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ def create_jwt_token(payload):                                  â”‚
â”‚     secret = os.getenv("JWT_KEY")                               â”‚
â”‚     token = jwt.encode(payload, secret, algorithm="HS256")      â”‚
â”‚     return token                                                â”‚
â”‚                                                                 â”‚
â”‚ # No error handling, no expiration!                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User Reviews & Provides Feedback:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ— Reject                                                     â”‚
â”‚                                                              â”‚
â”‚ Critique: "Add token expiration, error handling, and        â”‚
â”‚           validate the payload structure. Also add a        â”‚
â”‚           verification function."                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼ (Item 15: Restart full workflow, preserve context)

ITERATION 2:
â”â”â”â”â”â”â”â”â”â”â”

Backend receives user_feedback:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Restart Pipeline (Orchestrator Phase)                â”‚
â”‚                                                           â”‚
â”‚ 2. Context Preservation:                                â”‚
â”‚    âœ“ Reuse retrieved files/functions from Phase 1       â”‚
â”‚    âœ— Reset code generation output                       â”‚
â”‚                                                           â”‚
â”‚ 3. Orchestrator re-analyzes:                            â”‚
â”‚    - Original query: "Implement JWT auth"               â”‚
â”‚    - User feedback: "Add expiration, error handling,    â”‚
â”‚      validation, verification function"                  â”‚
â”‚    - Enhanced reasoning: "Need production-grade JWT     â”‚
â”‚      with error handling, expiration, and validation"   â”‚
â”‚                                                           â”‚
â”‚ 4. Re-route to code_generation with new context        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼

Generated Code (v2):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ import jwt                                                    â”‚
â”‚ from datetime import datetime, timedelta                     â”‚
â”‚ from typing import Optional, Dict                            â”‚
â”‚                                                              â”‚
â”‚ def create_jwt_token(payload: Dict, expires_in: int = 3600):â”‚
â”‚     try:                                                     â”‚
â”‚         secret = os.getenv("JWT_KEY")                        â”‚
â”‚         if not secret:                                       â”‚
â”‚             raise ValueError("JWT_KEY not configured")       â”‚
â”‚         if not isinstance(payload, dict):                    â”‚
â”‚             raise TypeError("Payload must be a dict")        â”‚
â”‚                                                              â”‚
â”‚         payload["exp"] = datetime.utcnow() +                 â”‚
â”‚                          timedelta(seconds=expires_in)       â”‚
â”‚         token = jwt.encode(payload, secret,                  â”‚
â”‚                           algorithm="HS256")                 â”‚
â”‚         return token                                         â”‚
â”‚     except Exception as e:                                   â”‚
â”‚         raise JWTError(f"Token creation failed: {e}")        â”‚
â”‚                                                              â”‚
â”‚ def verify_jwt_token(token: str) -> Optional[Dict]:         â”‚
â”‚     try:                                                     â”‚
â”‚         secret = os.getenv("JWT_KEY")                        â”‚
â”‚         payload = jwt.decode(token, secret,                  â”‚
â”‚                             algorithms=["HS256"])            â”‚
â”‚         return payload                                       â”‚
â”‚     except jwt.ExpiredSignatureError:                        â”‚
â”‚         raise JWTError("Token has expired")                  â”‚
â”‚     except jwt.InvalidTokenError:                            â”‚
â”‚         raise JWTError("Invalid token")                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User Reviews (v2):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ“ Accept Changes                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼

Apply to Workspace + Commit to Git:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ File: src/auth/jwt_handler.py (new)                      â”‚
â”‚ Action: CREATE (with generated code)                     â”‚
â”‚                                                          â”‚
â”‚ Git Commit:                                              â”‚
â”‚ "feat: Implement JWT authentication with expiration"     â”‚
â”‚ "- Add token creation with expiration handling"          â”‚
â”‚ "- Add token verification with error handling"           â”‚
â”‚ "- Add payload validation"                               â”‚
â”‚ "- Generated via Agentic IDE"                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SUMMARY:
â”â”â”â”â”â”

Iteration 1: 
  Phase 1 Retrieval: 2.5s â†’ Context ready
  Phase 2 Planning: 45s â†’ Workflow decided
  Phase 3 Code Gen: 60s â†’ Basic code
  Total: ~3-4 min

User Feedback: v1 â†’ v2 critique

Iteration 2:
  Phase 1 Retrieval: REUSED (0s)
  Phase 2 Planning: 45s â†’ Enhanced route
  Phase 3 Code Gen: 80s â†’ Production code
  Total: ~2-2.5 min (faster, reused context)

Total Time: ~5-6 minutes for production-quality code
```

---

## FLOW 5: Agent Failure & Retry (Orchestrator Decision Making)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AGENT FAILURE DETECTION & ADAPTIVE RETRIEVAL              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SCENARIO: Code Generation Produces Syntax Errors
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Agent Output:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ def my_function():                 â”‚
â”‚     x = [1, 2, 3                   â”‚  â† Missing closing bracket!
â”‚     return x                       â”‚
â”‚                                    â”‚
â”‚ failure_detector():                â”‚
â”‚   return {                         â”‚
â”‚     "is_failed": True,             â”‚
â”‚     "reason": "SyntaxError",       â”‚
â”‚     "details": "Line 2: unclosed"  â”‚
â”‚   }                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
Orchestrator Receives Failure:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check failure_info from code_gen agent                â”‚
â”‚ "is_failed": True                                      â”‚
â”‚                                                        â”‚
â”‚ Decision Logic:                                        â”‚
â”‚ IF failed AND attempts < max_attempts:                â”‚
â”‚     activate_adaptive_retrieval()                      â”‚
â”‚ ELSE:                                                  â”‚
â”‚     return_error_to_user()                             â”‚
â”‚                                                        â”‚
â”‚ Current: attempts = 1, max_attempts = 3               â”‚
â”‚ Decision: ACTIVATE ADAPTIVE RETRIEVAL                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
Adaptive Retrieval (Item 9 from spec):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Use failure info to refine retrieval:                  â”‚
â”‚                                                        â”‚
â”‚ Original query: "Implement function"                  â”‚
â”‚ Failure type: "SyntaxError"                            â”‚
â”‚ Enhanced query: "Implement function with correct      â”‚
â”‚                 Python syntax"                         â”‚
â”‚                                                        â”‚
â”‚ New retrieval with modified reasoning_guidance:       â”‚
â”‚ "Task: Fix syntax error, focus on bracket matching"   â”‚
â”‚                                                        â”‚
â”‚ Phase 1: Re-retrieve files with syntax emphasis       â”‚
â”‚ Phase 2: Re-extract functions with correct syntax     â”‚
â”‚          (filter examples with syntax errors)         â”‚
â”‚                                                        â”‚
â”‚ New context: ~2000 tokens (more syntax examples)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
Re-run Code Generation (Attempt 2):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ def my_function():                 â”‚
â”‚     x = [1, 2, 3]  â† Now correct!  â”‚
â”‚     return x                       â”‚
â”‚                                    â”‚
â”‚ failure_detector():                â”‚
â”‚   return {                         â”‚
â”‚     "is_failed": False,            â”‚
â”‚     "reason": "Success"            â”‚
â”‚   }                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
Proceed to Next Stage (Tests, etc.)
OR
Return Success to User


RETRY LOOP VISUALIZATION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Attempt 1: Syntax Error â”€â”€â”
                          â”œâ”€â”€â†’ Orchestrator Decision â”€â”€â†’ Adaptive Retrieval
Attempt 2: Success! â†â”€â”€â”€â”€â”€â”˜

Attempt 1: Bad logic â”€â”€â”
Attempt 2: Bad logic  â”œâ”€â”€â†’ Adaptive Retrieval (improved query)
Attempt 3: Success! â†â”€â”˜

Attempt 1: Failed â”€â”€â”
Attempt 2: Failed  â”œâ”€â”€â†’ Max retries exceeded
Attempt 3: Failed  â”‚
                   â””â”€â”€â†’ Return Error to User
```

---

## FLOW 6: Hybrid Search (Semantic + Keyword)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    TWO-PHASE RETRIEVAL WITH HYBRID SEARCH (Item 19)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 1: FILE-LEVEL RETRIEVAL (Hybrid)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

User Query: "Implement rate limiting middleware"

Step 1a: Semantic Search (Dense Vectors)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embedding Model: nomic-embed-text-v1.5 (CPU)          â”‚
â”‚ Query Vector: embed("rate limiting middleware")        â”‚
â”‚                                                         â”‚
â”‚ Qdrant Dense Vector Search:                            â”‚
â”‚ - Collection: workspace_files                          â”‚
â”‚ - Vector field: file_embedding                         â”‚
â”‚ - Top-k: 50                                            â”‚
â”‚ - Distance: Cosine                                     â”‚
â”‚ - Results:                                             â”‚
â”‚   1. auth/middleware.py (0.89)  â† Highest relevance   â”‚
â”‚   2. api/rate_limiter.py (0.87)                       â”‚
â”‚   3. config/limits.py (0.82)                          â”‚
â”‚   ...                                                  â”‚
â”‚   50. utils/logging.py (0.45)                         â”‚
â”‚                                                         â”‚
â”‚ Latency: ~800ms                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 1b: Keyword Search (Sparse Vectors via BM25)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BM25 Sparse Vector Search:                             â”‚
â”‚ - Query terms: ["rate", "limiting", "middleware"]      â”‚
â”‚ - BM25 params: k1=1.5, b=0.75                         â”‚
â”‚ - Results:                                             â”‚
â”‚   1. api/rate_limiter.py (BM25 score: 8.5)           â”‚
â”‚   2. tests/rate_limiter_test.py (7.2)                â”‚
â”‚   3. middleware.py (6.8)                              â”‚
â”‚   ...                                                  â”‚
â”‚                                                         â”‚
â”‚ Latency: ~200ms                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 1c: Hybrid Fusion (Combine Both)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fusion Strategy:                                        â”‚
â”‚ hybrid_score = 0.7 * semantic_score +                 â”‚
â”‚                0.3 * keyword_score                     â”‚
â”‚                                                         â”‚
â”‚ Normalized Results:                                    â”‚
â”‚ 1. auth/middleware.py                                 â”‚
â”‚    semantic: 0.89 (rank 1) â†’ 1.0 normalized          â”‚
â”‚    keyword: 0.68 (rank 3) â†’ 0.6 normalized           â”‚
â”‚    hybrid = 0.7 * 1.0 + 0.3 * 0.6 = 0.88            â”‚
â”‚                                                         â”‚
â”‚ 2. api/rate_limiter.py                               â”‚
â”‚    semantic: 0.87 (rank 2) â†’ 0.98 normalized         â”‚
â”‚    keyword: 0.85 (rank 1) â†’ 1.0 normalized           â”‚
â”‚    hybrid = 0.7 * 0.98 + 0.3 * 1.0 = 0.986 â† Winner! â”‚
â”‚                                                         â”‚
â”‚ Final Hybrid Ranking:                                  â”‚
â”‚ 1. api/rate_limiter.py (0.986)                        â”‚
â”‚ 2. auth/middleware.py (0.88)                          â”‚
â”‚ 3. config/limits.py (0.75)                            â”‚
â”‚ ...                                                    â”‚
â”‚ 50. utils/logging.py (0.42)                           â”‚
â”‚                                                         â”‚
â”‚ Total Phase 1 Latency: ~1.5 seconds                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 2: FUNCTION-LEVEL AST RETRIEVAL
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

From Phase 1 files, extract functions via AST:

Step 2a: Selective AST Parsing
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parse top Phase 1 files (max 50 files)                â”‚
â”‚ Extract:                                               â”‚
â”‚   - Functions with docstrings mentioning "rate"       â”‚
â”‚   - Classes with "Limiter" in name                    â”‚
â”‚   - Methods that return/check limits                  â”‚
â”‚                                                         â”‚
â”‚ From api/rate_limiter.py:                             â”‚
â”‚   1. class RateLimiter                                â”‚
â”‚   2. def apply_rate_limit(user_id, limit)            â”‚
â”‚   3. def check_quota(user_id)                         â”‚
â”‚   4. def reset_counters()                             â”‚
â”‚                                                         â”‚
â”‚ From auth/middleware.py:                              â”‚
â”‚   1. def rate_limit_middleware(request)              â”‚
â”‚   2. def get_user_rate_limit(user_id)                â”‚
â”‚                                                         â”‚
â”‚ ~20-30 functions extracted                            â”‚
â”‚ Latency: ~600ms                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2b: Semantic Re-ranking (Cross-Encoder)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model: ms-marco-MiniLM-L12-v2 (CPU)                   â”‚
â”‚                                                         â”‚
â”‚ Score each function pair:                              â”‚
â”‚ Query vs Function Signature + Docstring                â”‚
â”‚                                                         â”‚
â”‚ Scores:                                                â”‚
â”‚ 1. class RateLimiter (0.92) â† Most relevant           â”‚
â”‚ 2. def apply_rate_limit() (0.89)                      â”‚
â”‚ 3. def rate_limit_middleware() (0.85)                 â”‚
â”‚ 4. def check_quota() (0.78)                           â”‚
â”‚ ...                                                    â”‚
â”‚ 28. def reset_counters() (0.52)                       â”‚
â”‚                                                         â”‚
â”‚ Keep Top-20 functions                                 â”‚
â”‚ Latency: ~400ms                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2c: Deduplication (Semantic)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Remove redundant functions:                            â”‚
â”‚ - apply_rate_limit() and check_quota() both check    â”‚
â”‚   limits, keep apply_rate_limit() (higher score)      â”‚
â”‚                                                         â”‚
â”‚ Final context: 15-18 functions, ~2500 tokens          â”‚
â”‚ Latency: ~100ms                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL PHASE 1 + 2 LATENCY: ~3 seconds
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Result Quality Improvement:
Semantic Only (Phase 1 naive):    Precision 0.65
+ Keyword (Hybrid):               Precision 0.78
+ Function Reranking:             Precision 0.88 â† 35% better!
```

---

## FLOW 7: Model Loading & VRAM Management

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MODEL LOADING STRATEGY: Persistent Orchestrator + Workers    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STARTUP PHASE:
â”â”â”â”â”â”â”â”â”â”â”â”â”

Backend Boot:
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Init Ollama Connection (http://localhost:11434)   â”‚
â”‚    Check if Ollama is running                        â”‚
â”‚    if not: raise error, guide user to start Ollama  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Pre-load Orchestrator Model                       â”‚
â”‚    Endpoint: POST /api/generate                      â”‚
â”‚    Model: mistral-7b-instruct-v0.3                   â”‚
â”‚    Quantization: Q4_K_M                              â”‚
â”‚    keep_alive: "-1"  (indefinite VRAM persistence)   â”‚
â”‚    Warm-up: Generate 1 token to load model          â”‚
â”‚                                                       â”‚
â”‚    Response:                                         â”‚
â”‚    âœ“ Model loaded, VRAM: 4.2GB                      â”‚
â”‚    âœ“ Latency: 8-10 seconds (one-time only)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Orchestrator ALWAYS LOADED â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


DURING WORKFLOW EXECUTION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Retrieval Phase (CPU-bound, GPU free):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU VRAM State: 4.2GB (Orchestrator)     â”‚
â”‚                                           â”‚
â”‚ Embedding: CPU (no GPU)                  â”‚
â”‚ Reranker: CPU (no GPU)                   â”‚
â”‚                                           â”‚
â”‚ GPU Available: 16GB - 4.2GB = 11.8GB     â”‚
â”‚ Safe buffer: 1-2GB                       â”‚
â”‚ Current Load: ~26% of GPU                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Planning Phase (Orchestrator):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU VRAM State: 4.2GB (Orchestrator)     â”‚
â”‚ Keep model in VRAM                       â”‚
â”‚ Process: Route to next stage             â”‚
â”‚ Latency: 45 seconds                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Code Generation Phase (Worker Model):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Option A: REUSE Orchestrator             â”‚
â”‚   VRAM: 4.2GB (no change)                â”‚
â”‚   Latency: 0s (no reload)                â”‚
â”‚   Quality: Good (same Mistral-7B)        â”‚
â”‚   Recommended âœ“                          â”‚
â”‚                                           â”‚
â”‚ Option B: LOAD Different Model           â”‚
â”‚   Unload Orchestrator: -4.2GB            â”‚
â”‚   Load CodeLlama-7B: +4.2GB              â”‚
â”‚   Latency: 5-7s (reload)                 â”‚
â”‚   Quality: Excellent (CodeLlama)         â”‚
â”‚   Cost: Extra reload latency             â”‚
â”‚                                           â”‚
â”‚ Decision: Use Option A for speed         â”‚
â”‚   If time permits: Can use Option B      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After Code Generation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU VRAM State: 4.2GB (Mistral still)    â”‚
â”‚ (Model remains, keep_alive="-1")         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Test Generation Phase (Same Model):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU VRAM State: 4.2GB                    â”‚
â”‚ Reuse Mistral for test generation        â”‚
â”‚ Latency: ~50 seconds                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After Test Generation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU VRAM State: 4.2GB (Mistral persists) â”‚
â”‚ Ready for next user query                â”‚
â”‚ No reload needed!                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


VRAM OVER TIME:
â”â”â”â”â”â”â”â”â”â”â”â”â”

VRAM Usage (MB)
â”‚
â”‚  5000 â”€â”
â”‚        â”‚ â”Œâ”€â”€â”€ Orchestrator loaded (persistent)
â”‚        â”‚ â”‚
â”‚  4500 â”€â”¼â”€â”¤
â”‚        â”‚ â”‚
â”‚  4000 â”€â”¤ â”‚
â”‚        â”‚ â”‚ (stays loaded for all phases)
â”‚  3500 â”€â”¤ â”‚
â”‚        â”‚ â”‚
â”‚  3000 â”€â”¤ â”‚
â”‚        â”‚ â”‚
â”‚  2500 â”€â”¤ â”‚
â”‚        â”‚ â”‚
â”‚  2000 â”€â”¤ â”‚
â”‚        â”‚ â”‚
â”‚  1500 â”€â”¤ â”‚
â”‚        â”‚ â”‚
â”‚  1000 â”€â”¤ â”‚
â”‚        â”‚ â”‚
â”‚   500 â”€â”¤ â”‚
â”‚        â”‚ â”‚
â”‚     0 â”€â”´â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Time
â”‚           Phase1  Phase2  Phase3  Phase4
â”‚        Retrieval  Plan    CodeGen  Test
â”‚

Key: Model stays loaded, zero unload/reload cycles!


MONITORING & ALERTS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ /debug/vram endpoint provides:              â”‚
â”‚                                              â”‚
â”‚ {                                            â”‚
â”‚   "vram_used_mb": 4234,                     â”‚
â”‚   "vram_available_mb": 11766,               â”‚
â”‚   "percentage": 26.5,                       â”‚
â”‚   "peak_mb": 4234,                          â”‚
â”‚   "components": {                           â”‚
â”‚     "mistral_7b": 4200,                     â”‚
â”‚     "gui": 34                               â”‚
â”‚   }                                          â”‚
â”‚ }                                            â”‚
â”‚                                              â”‚
â”‚ Alert thresholds:                           â”‚
â”‚ - Warning: > 70% (11.2GB)                   â”‚
â”‚ - Critical: > 90% (14.4GB)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## FLOW 8: Package Deployment (Nix Flakes - Separate Processes)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     DEPLOYMENT: Three Independent Packages via Nix Flakes       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

flake.nix Structure:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚ flake {                                                         â”‚
â”‚   outputs = { self, nixpkgs, ... }:                            â”‚
â”‚                                                                 â”‚
â”‚   packages.x86_64-linux = {                                    â”‚
â”‚     agentic-ide-gui = <GUI Package>                            â”‚
â”‚     agentic-ide-backend = <Backend Package>                    â”‚
â”‚     agentic-ide-vectordb = <VectorDB Package>                  â”‚
â”‚   };                                                           â”‚
â”‚                                                                 â”‚
â”‚ }                                                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Runtime Start-Up Flow:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Terminal 1: Start Vector Database
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ $ nix run .#agentic-ide-vectordb â”‚
â”‚                                   â”‚
â”‚ Starting Qdrant server            â”‚
â”‚ Listening on: http://localhost:6333
â”‚ Health check: âœ“ OK                â”‚
â”‚ âœ“ Ready                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Terminal 2: Start Backend (Agent Network)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ $ nix run .#agentic-ide-backend  â”‚
â”‚                                   â”‚
â”‚ Connecting to Qdrant...           â”‚
â”‚ âœ“ Connected to localhost:6333    â”‚
â”‚                                   â”‚
â”‚ Initializing Ollama...            â”‚
â”‚ Checking http://localhost:11434  â”‚
â”‚ âœ“ Ollama ready                   â”‚
â”‚                                   â”‚
â”‚ Pre-loading Mistral-7B...         â”‚
â”‚ âœ“ Model loaded (4.2GB VRAM)      â”‚
â”‚                                   â”‚
â”‚ Starting ACP Server...            â”‚
â”‚ Listening on: http://localhost:8000
â”‚ Endpoints:                        â”‚
â”‚   POST /api/workflow/submit       â”‚
â”‚   GET  /api/workflow/{id}/stream  â”‚
â”‚   GET  /debug/metrics             â”‚
â”‚   GET  /debug/vram                â”‚
â”‚ âœ“ Backend ready                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Terminal 3: Start GUI Client
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ $ nix run .#agentic-ide-gui      â”‚
â”‚                                   â”‚
â”‚ Reading config/gui_config.yaml    â”‚
â”‚ Backend endpoint: localhost:8000  â”‚
â”‚ VectorDB endpoint: localhost:6333 â”‚
â”‚                                   â”‚
â”‚ Connecting to backend...          â”‚
â”‚ âœ“ Connected                       â”‚
â”‚                                   â”‚
â”‚ Checking version compatibility:   â”‚
â”‚ GUI: 1.0                          â”‚
â”‚ Backend: 1.0                      â”‚
â”‚ âœ“ Compatible                      â”‚
â”‚                                   â”‚
â”‚ GUI Window Opens                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Agentic IDE v1.0               â”‚â”‚
â”‚ â”‚                                â”‚â”‚
â”‚ â”‚ [Interaction Window]           â”‚â”‚
â”‚ â”‚ "Enter feature request..."     â”‚â”‚
â”‚ â”‚                                â”‚â”‚
â”‚ â”‚ [Main Diff View]               â”‚â”‚
â”‚ â”‚ (awaiting input)               â”‚â”‚
â”‚ â”‚                                â”‚â”‚
â”‚ â”‚ Footer: âœ“ Backend ready        â”‚â”‚
â”‚ â”‚         âœ“ Database ready       â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ âœ“ GUI ready                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


INTER-PROCESS COMMUNICATION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

         GUI                Backend              VectorDB
       (Rust)           (Python)               (Qdrant)
         â”‚                  â”‚                     â”‚
         â”‚  HTTP            â”‚                     â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚                     â”‚
         â”‚  /api/workflow    â”‚                     â”‚
         â”‚  submit           â”‚                     â”‚
         â”‚                   â”‚  HTTP              â”‚
         â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
         â”‚                   â”‚  /search query     â”‚
         â”‚                   â”‚  retrieve files    â”‚
         â”‚                   â”‚                     â”‚
         â”‚                   â”‚  JSON response     â”‚
         â”‚  ACP Callback     â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         â”‚  (streaming)      â”‚  (file results)     â”‚
         â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
         â”‚  /api/.../stream  â”‚                     â”‚
         â”‚  token: "def"     â”‚                     â”‚
         â”‚  token: "foo"     â”‚                     â”‚
         â”‚  token: "("...    â”‚  (Ollama queries   â”‚
         â”‚                   â”‚   happen locally   â”‚
         â”‚                   â”‚   via stdio, not   â”‚
         â”‚                   â”‚   over network)    â”‚
         â”‚                   â”‚                     â”‚
         â”‚  Final result     â”‚                     â”‚
         â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
         â”‚                   â”‚                     â”‚

Key: Each package is independent process
     GUI â† â†’ Backend â† â†’ VectorDB
     Packages can be updated/restarted independently


NEVERUP STATUS CHECK:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

All processes running:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ $ pgrep -f nix.*agentic-ide              â”‚
â”‚                                           â”‚
â”‚ 2847  /nix/.../bin/qdrant ...            â”‚
â”‚ 2948  python3 -m backend.main ...        â”‚
â”‚ 3051  /nix/.../bin/agentic-ide-gui ...   â”‚
â”‚                                           â”‚
â”‚ âœ“ All 3 processes active                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


STOPPING SERVICES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Method 1: Kill each terminal
$ Ctrl+C (in each terminal)

Method 2: Create systemd units (optional)
$ nix develop  # Then use systemctl


STATE ACROSS RESTARTS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Qdrant: Persists data to disk
        Files: ~/.local/share/qdrant/

Backend: Restarts fresh, reloads model
         LangGraph checkpoints persisted to disk
         (Location: config/checkpoints/)

GUI: Restarts fresh, reconnects to backend
     No local state lost (backend has it)

Result: Services can be restarted anytime
        All data persisted, workflows resumable
```

---

## SUMMARY TABLE: All Flows

| Flow | Use Case | Key Components | Duration | Status |
|------|----------|---|---|---|
| Flow 1 | System Architecture | GUI â†” Backend â†” VectorDB | â€” | Overview |
| Flow 2 | Feature Implementation | 4-stage workflow | 3-8 min | Main |
| Flow 3 | Real-Time Streaming | ACP callbacks | ~100-200ms/cb | Live |
| Flow 4 | User Feedback | Iterative refinement | 2-6 min/iter | Refinement |
| Flow 5 | Agent Failure | Retry + adaptive retrieval | 30-120 sec | Recovery |
| Flow 6 | Hybrid Search | Semantic + keyword | ~3 sec | Retrieval |
| Flow 7 | Model Loading | Persistent orchestrator | ~4.2GB VRAM | Optimization |
| Flow 8 | Deployment | 3-package Nix setup | â€” | DevOps |

